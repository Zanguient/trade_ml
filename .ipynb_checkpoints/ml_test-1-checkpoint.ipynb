{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 1\n",
    "##### Programação grosseira em busca dos melhores dados e dos melhores modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn import metrics\n",
    "from warnings import simplefilter\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (25, 8)\n",
    "#sns.set_style('whitegrid')\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1642, 522)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/dataset_cler.csv', sep=\";\", encoding='utf-16')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ampl_40</th>\n",
       "      <th>desv_amp_40</th>\n",
       "      <th>body_40</th>\n",
       "      <th>body_per_40</th>\n",
       "      <th>pavio_sup_40</th>\n",
       "      <th>pavio_sup_per_40</th>\n",
       "      <th>pavio_inf_40</th>\n",
       "      <th>pavio_inf_per_40</th>\n",
       "      <th>high_dist_40</th>\n",
       "      <th>low_dist_40</th>\n",
       "      <th>...</th>\n",
       "      <th>pavio_inf_m15_0</th>\n",
       "      <th>pavio_inf_per_m15_0</th>\n",
       "      <th>high_dist_m15_0</th>\n",
       "      <th>low_dist_m15_0</th>\n",
       "      <th>type_m15_0</th>\n",
       "      <th>atr</th>\n",
       "      <th>qt_bars</th>\n",
       "      <th>oper</th>\n",
       "      <th>take</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>40.0</td>\n",
       "      <td>53.33</td>\n",
       "      <td>25.0</td>\n",
       "      <td>33.33</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.33</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>down</td>\n",
       "      <td>58.21</td>\n",
       "      <td>5</td>\n",
       "      <td>Sell</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>55.0</td>\n",
       "      <td>61.11</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>51.11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>up</td>\n",
       "      <td>66.07</td>\n",
       "      <td>6</td>\n",
       "      <td>Sell</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>Loss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 522 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ampl_40  desv_amp_40  body_40  body_per_40  pavio_sup_40  pavio_sup_per_40  \\\n",
       "0     75.0         1.50     40.0        53.33          25.0             33.33   \n",
       "1     90.0         0.78     55.0        61.11          35.0             38.89   \n",
       "\n",
       "   pavio_inf_40  pavio_inf_per_40  high_dist_40  low_dist_40  ...  \\\n",
       "0          10.0             13.33          15.0         10.0  ...   \n",
       "1           0.0              0.00          70.0         95.0  ...   \n",
       "\n",
       "  pavio_inf_m15_0  pavio_inf_per_m15_0  high_dist_m15_0  low_dist_m15_0  \\\n",
       "0            10.0                22.22              5.0           205.0   \n",
       "1           115.0                51.11             20.0            40.0   \n",
       "\n",
       "   type_m15_0    atr  qt_bars  oper  take  status  \n",
       "0        down  58.21        5  Sell  20.0    Gain  \n",
       "1          up  66.07        6  Sell -40.0    Loss  \n",
       "\n",
       "[2 rows x 522 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gain    1099\n",
       "Loss     543\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[(df['status']!='Loss') & (df['status']!='Gain')].index.values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gain    1099\n",
       "Loss     543\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#train_features = df.columns.difference(['take', 'status', 'oper'])\n",
    "X = df.drop(['take','status','oper'], axis=1) #df[train_features]\n",
    "y = df['status']\n",
    "\n",
    "x_columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 21, 32, 43, 54, 65, 76, 87, 98, 109]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_features_category = []\n",
    "for index, col in enumerate(X.columns):\n",
    "    if X.dtypes[index]=='object':\n",
    "        index_features_category.append(index)\n",
    "index_features_category[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(['inside', 'up', 'down'])\n",
    "columns_categorical = X.select_dtypes(include=['object']).columns\n",
    "for col_cat in columns_categorical:\n",
    "    X[col_cat] = encoder.transform(X[col_cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ohe = OneHotEncoder(categorical_features=index_features_category)\n",
    "X = ohe.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fit(X_train, X_test, y_train, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(accuracy)\n",
    "    return y_pred \n",
    "\n",
    "def fitAll(X_train, X_test, y_train, y_test, algorithms):\n",
    "    similaridade = []\n",
    "    for item in algorithms:\n",
    "        name = item[0]\n",
    "        algorithm = item[1]\n",
    "        \n",
    "        algorithm.fit(X_train, y_train)\n",
    "        y_pred = algorithm.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        #print(name, ' => ', accuracy)\n",
    "        similaridade.append((accuracy, name))\n",
    "        \n",
    "    similaridade.sort()\n",
    "    similaridade.reverse()\n",
    "    \n",
    "    for j in similaridade:\n",
    "        print(j)\n",
    "\n",
    "def f_importances(coef, names):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "standar = StandardScaler()\n",
    "standar.fit(X)\n",
    "X = standar.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6835699797160243, 'SVC')\n",
      "(0.6470588235294118, 'KNeighborsClassifier')\n",
      "(0.6389452332657201, 'GradientBoostingClassifier')\n",
      "(0.6206896551724138, 'RandomForestClassifier')\n",
      "(0.5821501014198783, 'LogisticRegression')\n",
      "(0.5801217038539553, 'MLPClassifier')\n",
      "(0.5780933062880325, 'RidgeClassifier')\n",
      "(0.5618661257606491, 'DecisionTreeClassifier')\n",
      "(0.460446247464503, 'GaussianNB')\n"
     ]
    }
   ],
   "source": [
    "algorithms = []\n",
    "\n",
    "algorithms.append(['DecisionTreeClassifier', DecisionTreeClassifier(random_state=0)])\n",
    "algorithms.append(['RandomForestClassifier', RandomForestClassifier(n_estimators=10, random_state=0)])\n",
    "algorithms.append(['GaussianNB', GaussianNB()])\n",
    "algorithms.append(['RidgeClassifier', RidgeClassifier()])\n",
    "algorithms.append(['MLPClassifier', MLPClassifier(random_state=True, max_iter=1000, learning_rate_init=0.0001, hidden_layer_sizes=(89))])\n",
    "algorithms.append(['GradientBoostingClassifier', GradientBoostingClassifier()])\n",
    "algorithms.append(['SVC', SVC(gamma='auto')])\n",
    "algorithms.append(['KNeighborsClassifier', KNeighborsClassifier()])\n",
    "algorithms.append(['LogisticRegression', LogisticRegression()])\n",
    "\n",
    "fitAll(X_train, X_test, y_train, y_test, algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test = GradientBoostingClassifier(learning_rate=0.1, n_estimators=1000)\n",
    "y_pred = fit(X_train, X_test, y_train, y_test, test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701    Gain\n",
       "Name: status, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[300:301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12371134, 0.31770833, 0.2       , 0.6154    , 0.        ,\n",
       "       0.        , 0.13157895, 0.42305577, 0.04142012, 0.13513514,\n",
       "       0.        , 0.03787879, 0.0153417 , 0.00900901, 0.1429    ,\n",
       "       0.21428571, 0.97954286, 0.        , 0.        , 0.03773585,\n",
       "       0.03071672, 0.        , 0.07142857, 0.1122449 , 0.07575758,\n",
       "       0.5       , 0.15151515, 0.53573342, 0.        , 0.        ,\n",
       "       0.02150538, 0.00952381, 1.        , 0.17117117, 0.23651961,\n",
       "       0.1369863 , 0.4762    , 0.03571429, 0.05077333, 0.34482759,\n",
       "       0.5357183 , 0.02469136, 0.08379888, 0.        , 0.22619048,\n",
       "       0.0990991 , 0.11842105, 0.4286    , 0.12244898, 0.31426686,\n",
       "       0.20689655, 0.32651429, 0.02339181, 0.02547771, 1.        ,\n",
       "       0.13559322, 0.04600812, 0.01818182, 0.0909    , 0.2       ,\n",
       "       0.58186667, 0.1       , 0.399956  , 0.        , 0.21276596,\n",
       "       0.        , 0.06493506, 0.07131537, 0.01639344, 0.1429    ,\n",
       "       0.12      , 0.50649965, 0.1       , 0.46754663, 0.01515152,\n",
       "       0.00507614, 1.        , 0.24731183, 0.45187166, 0.20238095,\n",
       "       0.68      , 0.22222222, 0.2599935 , 0.04347826, 0.08999888,\n",
       "       0.08878505, 0.00606061, 1.        , 0.22727273, 0.06082725,\n",
       "       0.140625  , 0.5294    , 0.08333333, 0.12664226, 0.24      ,\n",
       "       0.38818612, 0.04395604, 0.0625    , 0.        , 0.04123711,\n",
       "       0.03862213, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.09090909, 0.00719424, 0.5       ,\n",
       "       0.11702128, 0.15899582, 0.03773585, 0.1538    , 0.        ,\n",
       "       0.        , 0.35483871, 0.91126427, 0.01960784, 0.0625    ,\n",
       "       1.        , 0.05369128, 0.08112094, 0.02439024, 0.2       ,\n",
       "       0.09090909, 0.32306698, 0.09090909, 0.56663645, 0.04347826,\n",
       "       0.0546875 , 1.        , 0.13106796, 0.18473074, 0.04020101,\n",
       "       0.2759    , 0.4       , 0.29429333, 0.37142857, 0.47818667,\n",
       "       0.0397351 , 0.06701031, 0.        , 0.11111111, 0.03465982,\n",
       "       0.125     , 0.7857    , 0.03571429, 0.07734807, 0.07142857,\n",
       "       0.16331429, 0.04854369, 0.13513514, 1.        , 0.23809524,\n",
       "       0.17018634, 0.17460317, 0.5       , 0.13888889, 0.24895947,\n",
       "       0.19354839, 0.30678367, 0.04123711, 0.03883495, 0.        ,\n",
       "       0.08849558, 0.03645833, 0.01587302, 0.0833    , 0.15      ,\n",
       "       0.56249297, 0.19230769, 0.45836542, 0.19298246, 0.015625  ,\n",
       "       0.        , 0.08888889, 0.12280702, 0.08333333, 0.5       ,\n",
       "       0.16666667, 0.33762704, 0.05172414, 0.22961534, 0.05882353,\n",
       "       0.01481481, 1.        , 0.16494845, 0.12765957, 0.11764706,\n",
       "       0.5556    , 0.        , 0.        , 0.25      , 0.4814213 ,\n",
       "       0.01333333, 0.03167421, 0.        , 0.35294118, 0.23518519,\n",
       "       0.1147541 , 0.2692    , 0.06451613, 0.08281284, 0.5862069 ,\n",
       "       0.73551581, 0.05882353, 0.10638298, 0.        , 0.16666667,\n",
       "       0.07808219, 0.09090909, 0.3       , 0.47619048, 0.5499945 ,\n",
       "       0.08163265, 0.21817388, 0.01010101, 0.04060914, 0.        ,\n",
       "       0.13924051, 0.05418719, 0.01282051, 0.0769    , 0.13793103,\n",
       "       0.33333333, 0.38095238, 0.70331429, 0.15853659, 0.06818182,\n",
       "       0.        , 0.09      , 0.09985935, 0.10714286, 0.8182    ,\n",
       "       0.02777778, 0.09739634, 0.01818182, 0.099989  , 0.06060606,\n",
       "       0.08695652, 1.        , 0.13392857, 0.16566627, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14583333, 0.07619048, 0.5       , 0.26436782, 0.25865209,\n",
       "       0.14285714, 0.4231    , 0.28571429, 0.41024   , 0.10638298,\n",
       "       0.20708594, 0.01385042, 0.00930233, 1.        , 0.27272727,\n",
       "       0.07407407, 0.1641791 , 0.4231    , 0.20289855, 0.57214195,\n",
       "       0.01923077, 0.04277778, 0.06153846, 0.06299213, 1.        ,\n",
       "       0.05925926, 0.01736466, 0.07594937, 0.6       , 0.        ,\n",
       "       0.        , 0.06896552, 0.44999438, 0.05223881, 0.00865801,\n",
       "       0.        , 0.08247423, 0.16405434, 0.075     , 0.3333    ,\n",
       "       0.175     , 0.4188025 , 0.06578947, 0.31748571, 0.00465116,\n",
       "       0.03608247, 0.        , 0.0776699 , 0.04854369, 0.05882353,\n",
       "       0.5       , 0.125     , 0.34285714, 0.0625    , 0.21666125,\n",
       "       0.05882353, 0.02469136, 1.        , 0.08208955, 0.07854985,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.05      , 0.0375    , 0.5       , 0.275     ,\n",
       "       0.31318681, 0.35087719, 0.8       , 0.1       , 0.12999675,\n",
       "       0.06451613, 0.0861512 , 0.18055556, 0.01492537, 1.        ,\n",
       "       0.06716418, 0.02815433, 0.05063291, 0.3333    , 0.24137931,\n",
       "       0.63189254, 0.01724138, 0.09255556, 0.02216066, 0.04883721,\n",
       "       1.        , 0.10447761, 0.08074534, 0.01694915, 0.1111    ,\n",
       "       0.24      , 0.73684792, 0.08333333, 0.24688889, 0.00806452,\n",
       "       0.01652893, 0.        , 0.06818182, 0.16720257, 0.01801802,\n",
       "       0.1818    , 0.17391304, 0.39155718, 0.2       , 0.48944648,\n",
       "       0.        , 0.03225806, 1.        , 0.2       , 0.18618989,\n",
       "       0.22666667, 0.8947    , 0.08695652, 0.11232   , 0.        ,\n",
       "       0.        , 0.18987342, 0.10447761, 1.        , 0.35869565,\n",
       "       0.17325228, 0.38983051, 0.6571    , 0.11428571, 0.12192   ,\n",
       "       0.17391304, 0.26375909, 0.03      , 0.13978495, 0.        ,\n",
       "       0.35714286, 0.07258065, 0.21818182, 0.4444    , 0.15625   ,\n",
       "       0.21165714, 0.25641026, 0.39888003, 0.26829268, 0.05555556,\n",
       "       1.        , 0.1409396 , 0.05097087, 0.109375  , 0.6087    ,\n",
       "       0.10714286, 0.14042645, 0.22222222, 0.28698713, 0.01675978,\n",
       "       0.00485437, 0.        , 0.17777778, 0.11208406, 0.07142857,\n",
       "       0.3158    , 0.22580645, 0.42982149, 0.25      , 0.37319783,\n",
       "       0.05925926, 0.02424242, 0.        , 0.28205128, 0.13959391,\n",
       "       0.21126761, 0.6       , 0.        , 0.        , 0.3125    ,\n",
       "       0.44999438, 0.06349206, 0.12857143, 0.        , 0.37383178,\n",
       "       0.23924269, 0.33333333, 0.8372    , 0.        , 0.        ,\n",
       "       0.35      , 0.18994283, 0.12037037, 0.47692308, 0.        ,\n",
       "       0.17757009, 0.07961783, 0.05454545, 0.1364    , 0.18367347,\n",
       "       0.43465788, 0.20408163, 0.47842105, 0.38709677, 0.03030303,\n",
       "       1.        , 0.11838006, 0.04617414, 0.04166667, 0.2653    ,\n",
       "       0.27906977, 0.5360035 , 0.09756098, 0.28573095, 0.03472222,\n",
       "       0.07164179, 1.        , 0.12886598, 0.11336516, 0.13108614,\n",
       "       0.625     , 0.08333333, 0.14090858, 0.1147541 , 0.28017483,\n",
       "       0.0703125 , 0.03125   , 1.        , 0.08411215, 0.06732118,\n",
       "       0.01282051, 0.1082665 , 0.17647059, 0.61839749, 0.10569106,\n",
       "       0.36911955, 0.04516129, 0.08839779, 0.        , 0.07591623,\n",
       "       0.10084034, 0.00641026, 0.0488    , 0.24705882, 0.54524164,\n",
       "       0.14634146, 0.47367285, 0.0155642 , 0.01988636, 0.        ,\n",
       "       0.17283951, 0.18846695, 0.11217949, 0.5469    , 0.04545455,\n",
       "       0.08925714, 0.22429907, 0.40180006, 0.0498615 , 0.01213592,\n",
       "       1.        , 0.23846154, 0.16765053, 0.18075802, 0.6392    ,\n",
       "       0.18487395, 0.25295561, 0.10569106, 0.14393126, 0.05151515,\n",
       "       0.04545455, 0.        , 0.29314572, 0.        ])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Positive/Positive Ok', conf_matrix[0][0])\n",
    "#print('Positive/Negative Er', conf_matrix[0][1])\n",
    "#print('Negative/Negative Ok', conf_matrix[1][0])\n",
    "#print('Negative/Positive Ok', conf_matrix[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf_ran' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-99b0b3dcd4e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf_importances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_ran\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf_ran' is not defined"
     ]
    }
   ],
   "source": [
    "clf_importances = dict(zip(x_columns, clf_ran.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ran.feature_importances_[0:10], len(clf_ran.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index = np.arange(len(x_columns[0:64]))\n",
    "plt.bar(index, clf_ran.feature_importances_[0:64])\n",
    "plt.xticks(index, x_columns, rotation='vertical')\n",
    "plt.title('clf_ran')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index = np.arange(len(x_columns[64:128]))\n",
    "plt.bar(index, clf_ran.feature_importances_[64:128])\n",
    "plt.xticks(index, x_columns, rotation='vertical')\n",
    "plt.title('clf_ran')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
