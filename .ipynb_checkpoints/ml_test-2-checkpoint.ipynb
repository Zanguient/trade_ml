{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste 2\n",
    "##### Agora é fazer testes e melhores validações dos 3 melhores modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from warnings import simplefilter\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5802, 412)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/dataset_cler.csv', sep=\";\", encoding='utf-16')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gain    3787\n",
       "Loss    2015\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.loc[(df['status']!='Loss') & (df['status']!='Gain')].index.values, inplace=True)\n",
    "df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['take','status','oper'], axis=1) #df[train_features]\n",
    "y = df['status']\n",
    "\n",
    "x_columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "columns_categorical = X.select_dtypes(include=['object']).columns\n",
    "for col_cat in columns_categorical:\n",
    "    X[col_cat] = encoder.fit_transform(X[col_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.83979328, 0.84926787, 0.84827586, 0.86551724, 0.83534483]),\n",
       " 0.8476398170423833)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "scores = cross_val_score(gbc, X, y, cv=5)\n",
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.86218777, 0.86821705, 0.86724138, 0.85258621, 0.84482759]),\n",
       " 0.8590119991683745)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = MLPClassifier()\n",
    "scores = cross_val_score(dl, X, y, cv=5)\n",
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.73901809, 0.79242033, 0.7637931 , 0.77844828, 0.77068966]),\n",
       " 0.7688738899284209)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "scores = cross_val_score(rfc, X, y, cv=5)\n",
    "scores, scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizando o modelo GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(n_estimators, learning_rate, min_samples_split, min_samples_leaf, max_depth, \n",
    "             max_features, subsample, params, cv = 5):\n",
    "  np.random.seed(0)\n",
    "\n",
    "  gbc = GradientBoostingClassifier(n_estimators = n_estimators,\n",
    "                                  learning_rate = learning_rate,\n",
    "                                  min_samples_split = min_samples_split,\n",
    "                                  min_samples_leaf = min_samples_leaf,\n",
    "                                  max_depth = max_depth,\n",
    "                                  max_features = max_features,\n",
    "                                  subsample = subsample,\n",
    "                                  random_state = 0)\n",
    "    \n",
    "  grid_search = GridSearchCV(estimator = gbc, param_grid = params, scoring = 'roc_auc',\n",
    "                             n_jobs = -1, iid = False, cv = cv)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "  results = grid_search.cv_results_\n",
    "  best_params = grid_search.best_params_\n",
    "  best_score = grid_search.best_score_\n",
    "  print(best_params, best_score)\n",
    "  \n",
    "  return gbc, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis para coletar os resultados\n",
    "models = np.array([])\n",
    "opt_params = dict()\n",
    "scores = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO 0\n",
    "learning_rate = 0.1\n",
    "n_estimators = None\n",
    "max_depth = 8\n",
    "min_samples_split = 250\n",
    "min_samples_leaf = 20\n",
    "max_features = 'sqrt'\n",
    "subsample = 0.8\n",
    "params = {'n_estimators': range(50, 151, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100} 0.8568400598118184\n"
     ]
    }
   ],
   "source": [
    "gbc, opt_param, score = optimize(n_estimators = n_estimators,\n",
    "                                 learning_rate = learning_rate,\n",
    "                                 min_samples_split = min_samples_split,\n",
    "                                 min_samples_leaf = min_samples_leaf,\n",
    "                                 max_depth = max_depth,\n",
    "                                 max_features = max_features,\n",
    "                                 subsample = subsample,\n",
    "                                 params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando as variáveis com os resultados\n",
    "models = np.append(models, gbc)\n",
    "opt_params = {**opt_params, **opt_param}\n",
    "scores = np.append(scores, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO 1: Otimizando max_depth e min_samples_split\n",
    "n_estimators = opt_params['n_estimators']\n",
    "max_depth = None\n",
    "min_samples_split = None\n",
    "min_samples_leaf = 20\n",
    "max_features = 'sqrt'\n",
    "subsample = 0.8\n",
    "params = {'max_depth': range(3, 12, 2), 'min_samples_split': range(150, 401, 50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_samples_split': 150} 0.8641101606535772\n"
     ]
    }
   ],
   "source": [
    "gbc, opt_param, score = optimize(n_estimators = n_estimators,\n",
    "                                 learning_rate = learning_rate,\n",
    "                                 min_samples_split = min_samples_split,\n",
    "                                 min_samples_leaf = min_samples_leaf,\n",
    "                                 max_depth = max_depth,\n",
    "                                 max_features = max_features,\n",
    "                                 subsample = subsample,\n",
    "                                 params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando as variáveis com os resultados\n",
    "models = np.append(models, gbc)\n",
    "opt_params = {**opt_params, **opt_param}\n",
    "scores = np.append(scores, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO 2: Otimizando min_samples_leaf\n",
    "max_depth = opt_params['max_depth']\n",
    "min_samples_split = opt_params['min_samples_split']\n",
    "min_samples_leaf = None\n",
    "max_features = 'sqrt'\n",
    "subsample = 0.8\n",
    "params = {'min_samples_leaf': range(25, 61, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 25} 0.8686614133161905\n"
     ]
    }
   ],
   "source": [
    "gbc, opt_param, score = optimize(n_estimators = n_estimators,\n",
    "                                 learning_rate = learning_rate,\n",
    "                                 min_samples_split = min_samples_split,\n",
    "                                 min_samples_leaf = min_samples_leaf,\n",
    "                                 max_depth = max_depth,\n",
    "                                 max_features = max_features,\n",
    "                                 subsample = subsample,\n",
    "                                 params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando as variáveis com os resultados\n",
    "models = np.append(models, gbc)\n",
    "opt_params = {**opt_params, **opt_param}\n",
    "scores = np.append(scores, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO 3: Otimizando max_features\n",
    "min_samples_leaf = opt_params['min_samples_leaf']\n",
    "max_features = None\n",
    "subsample = 0.8\n",
    "params = {'max_features': range(21, 31, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 27} 0.8828589389246367\n"
     ]
    }
   ],
   "source": [
    "gbc, opt_param, score = optimize(n_estimators = n_estimators,\n",
    "                                 learning_rate = learning_rate,\n",
    "                                 min_samples_split = min_samples_split,\n",
    "                                 min_samples_leaf = min_samples_leaf,\n",
    "                                 max_depth = max_depth,\n",
    "                                 max_features = max_features,\n",
    "                                 subsample = subsample,\n",
    "                                 params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando as variáveis com os resultados\n",
    "models = np.append(models, gbc)\n",
    "opt_params = {**opt_params, **opt_param}\n",
    "scores = np.append(scores, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'max_depth': 9,\n",
       " 'min_samples_split': 150,\n",
       " 'min_samples_leaf': 25,\n",
       " 'max_features': 27}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otimizando subsample\n",
    "max_features = opt_params['max_features']\n",
    "subsample = None\n",
    "params = {'subsample': np.append(np.arange(0.6, 1, 0.05), 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 1.0} 0.8929108283977165\n"
     ]
    }
   ],
   "source": [
    "gbc, opt_param, score = optimize(n_estimators = n_estimators,\n",
    "                                 learning_rate = learning_rate,\n",
    "                                 min_samples_split = min_samples_split,\n",
    "                                 min_samples_leaf = min_samples_leaf,\n",
    "                                 max_depth = max_depth,\n",
    "                                 max_features = max_features,\n",
    "                                 subsample = subsample,\n",
    "                                 params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizando as variáveis com os resultados\n",
    "models = np.append(models, gbc)\n",
    "opt_params = {**opt_params, **opt_param}\n",
    "scores = np.append(scores, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'max_depth': 9,\n",
       " 'min_samples_split': 150,\n",
       " 'min_samples_leaf': 25,\n",
       " 'max_features': 27,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
